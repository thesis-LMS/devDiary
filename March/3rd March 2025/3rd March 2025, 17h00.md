## objective:
what is the goal of this session?
- evaluate Cursor
- understand if its "AI-first" approach offers a significantly different experience compared to AI plugins like Copilot or IntelliJ AI Assistant.

## activities:
tasks completed:
- similar to the previous two tbh
- found its ability to reference project files and context for chat-like interactions directly in the IDE to be quite seamless.

## tags:
 #cursor #evaluation 

## challenges:
problems or blockers encountered:
- even though i'm familiar with it, Kotlin on VS Code is just ðŸ‘Ž (a very personal preference)
- still encountered the generic exception issue, indicating this is a common trait of models not specifically fine-tuned for the project's exact conventions without explicit instruction.

## solutions/progress:
how were issues resolved?
- used its integrated chat/edit features to refine the exception handling for `getBookById`.

## next steps:
what will I work on next?
- evaluate Qodo, focusing on its specific claims around test understanding.

## reflection:
key takeaways, learnings, or insights:
- considering the scope of the thesis (comparing assistants/plugins rather than entire IDE replacements), Cursor might be less central to the final comparison unless it shows a unique advantage for the _TDD process itself_.